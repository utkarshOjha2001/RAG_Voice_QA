# ğŸ§ Voice RAG Assistant

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

A modern voice-based document interaction system powered by RAG (Retrieval-Augmented Generation)

<p align="center">
  <img src="assets/microphone.svg" alt="Voice RAG Assistant Logo" width="150"/>
</p>

</div>

## âœ¨ Features

- ğŸ¤ **Voice Interaction**: Natural voice-based queries for document interaction
- ğŸ“„ **Document Processing**: Support for PDF and TXT files
- ğŸ¤– **Intelligent Responses**: Powered by Google's Gemini AI
- ğŸ’¡ **RAG Architecture**: Enhanced responses using document context
- ğŸ¨ **Modern UI**: Beautiful, responsive design with glass morphism effects
- ğŸ”Š **Text-to-Speech**: Natural voice responses for better interaction

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/RAG_Voice_QA.git
   cd RAG_Voice_QA
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirement.txt
   ```

4. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Add your Google API key to .env file
   ```

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

## ğŸ› ï¸ Technology Stack

- **Frontend**: Streamlit with custom CSS
- **Backend**: Python 3.8+
- **AI Model**: Google Gemini
- **Vector Store**: Chroma DB
- **Speech Processing**: 
  - Speech Recognition
  - Google Text-to-Speech (gTTS)
- **Document Processing**: LangChain

## ğŸ’¡ How It Works

1. **Document Upload**: Upload your PDF or TXT document
2. **Processing**: Document is processed and stored in Chroma DB
3. **Voice Query**: Click the microphone button and ask your question
4. **RAG Processing**: 
   - Retrieves relevant context from the document
   - Generates response using Gemini AI
5. **Voice Response**: Converts the answer to speech

## ğŸ“ Project Structure

```
RAG_Voice_QA/
â”œâ”€â”€ app.py              # Main application file
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css      # Custom styling
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ microphone.svg # UI assets
â”œâ”€â”€ tmp/               # Temporary files
â”œâ”€â”€ chroma_db/         # Vector database
â””â”€â”€ requirement.txt    # Dependencies
```

## âš™ï¸ Configuration

Create a `.env` file with the following:

```env
GOOGLE_API_KEY=your_google_api_key_here
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Google Gemini AI for powerful language processing
- Streamlit for the amazing web framework
- LangChain for RAG implementation
- All contributors and users of this project

---

<div align="center">
Made with â¤ï¸ for the AI community
</div> 